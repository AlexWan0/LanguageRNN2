{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fadcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6284c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"device\"] = 'cuda'\n",
    "\n",
    "import sys\n",
    "sys.path.append('language/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca4978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "device = os.environ.get('device', 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa769ff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data import build_data\n",
    "\n",
    "sit2id, sid2uids, train_sit_id, valid_sit_id, situations, utterances = build_data(id_pairs='language/id_pairs_2.txt',\n",
    "                                                                                  situations='language/situations_2.txt',\n",
    "                                                                                  utterances='language/utterances_2.txt',\n",
    "                                                                                  training_set='language/training_set.txt',\n",
    "                                                                                  test_set='language/test_set.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efb6b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vocab import build_vocab\n",
    "\n",
    "v1, v2, eos_id, start_id = build_vocab(situations, utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import build_model\n",
    "\n",
    "(enc, opt_enc), (dec, opt_dec) = build_model(v1, v2, enc_lr=5e-4, dec_lr=5e-4)\n",
    "\n",
    "enc = enc.to(device)\n",
    "dec = dec.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec9ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import wrap_forward\n",
    "\n",
    "model_forward = wrap_forward(enc, dec, start_id, eos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde441e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import Plotter, RunningAvg\n",
    "\n",
    "train_loss_run = RunningAvg(10)\n",
    "plot = Plotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeness import beam_completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacdf6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampling import build_sampling\n",
    "\n",
    "run_sampling = True\n",
    "\n",
    "run_sampling = build_sampling(enc,\n",
    "                              dec,\n",
    "                              v2,\n",
    "                              start_id,\n",
    "                              eos_id,\n",
    "                              lr=1e-5,\n",
    "                              temperature=1.0,\n",
    "                              gen_length=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a592fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data import id_select\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "random.shuffle(train_sit_id)\n",
    "pbar = tqdm(train_sit_id)\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "for iter_idx, sit_id in enumerate(pbar):\n",
    "    utter_ids = sid2uids[sit_id]\n",
    "    \n",
    "    target_utters = id_select(utter_ids, utterances)\n",
    "    \n",
    "    input_sit_str = '^ ' + id_select([sit_id], situations)[0] + ' !'\n",
    "    input_sit = v1.tokenize(input_sit_str)\n",
    "    \n",
    "    tu = random.choice(target_utters) + ' !'\n",
    "    tu_target = v2.tokenize(tu)\n",
    "    \n",
    "    pred_ids, loss, logits_all = model_forward(input_sit.to(device),\n",
    "                                               force=True,\n",
    "                                               sample=False,\n",
    "                                               tu_target=tu_target.to(device),\n",
    "                                               loss_func=ce_loss,\n",
    "                                               gen_length=None)\n",
    "    \n",
    "    cleaned_pred = ' '.join(v2.decode(pred_ids)).replace('!', '').strip()\n",
    "    \n",
    "    if cleaned_pred in target_utters:\n",
    "        num_correct += 1\n",
    "    \n",
    "    loss.backward()\n",
    "    opt_dec.step()\n",
    "    opt_enc.step()\n",
    "    \n",
    "    opt_dec.zero_grad()\n",
    "    opt_enc.zero_grad()\n",
    "    \n",
    "    plot.add(loss = train_loss_run(loss.item()/len(pred_ids)), accuracy = num_correct/(iter_idx + 1))\n",
    "    \n",
    "    if iter_idx % 500 == 0:\n",
    "        eta = ''\n",
    "        if pbar.format_dict['rate'] != None:\n",
    "            eta = (pbar.format_dict['total'] - iter_idx) / pbar.format_dict['rate']\n",
    "        plot.output_show(suptitle=(cleaned_pred + \" | \" + tu.replace('!', '').strip() + \" | \" + str(eta)),\n",
    "                         subplots=(3, 3),\n",
    "                         figsize=(15, 10))\n",
    "    \n",
    "    if iter_idx % 500 == 0 and iter_idx != 0 and run_sampling:        \n",
    "        print('START SAMPLING:')\n",
    "        sampling_ids = random.sample(train_sit_id, 100)\n",
    "        for sampling_iter_idx, sit_id in enumerate(tqdm(sampling_ids)):\n",
    "            utter_ids = sid2uids[sit_id]\n",
    "    \n",
    "            target_utters = id_select(utter_ids, utterances)\n",
    "\n",
    "            input_sit_str = '^ ' + id_select([sit_id], situations)[0] + ' !'\n",
    "            input_sit = v1.tokenize(input_sit_str)\n",
    "            \n",
    "            '''comp_1 = beam_completeness(\n",
    "                                target_utters,\n",
    "                                input_sit,\n",
    "                                enc,\n",
    "                                dec,\n",
    "                                v2,\n",
    "                                start_id,\n",
    "                                eos_id,\n",
    "                                verbose=False)'''\n",
    "            #print('%d: PRE COMPLETENESS SINGLE SAMPLE: %.2f' % (sampling_iter_idx, comp_1))\n",
    "\n",
    "            run_sampling(input_sit.to(device), target_utters, num_samples=100)\n",
    "\n",
    "            '''comp_2 = beam_completeness(\n",
    "                                target_utters,\n",
    "                                input_sit,\n",
    "                                enc,\n",
    "                                dec,\n",
    "                                v2,\n",
    "                                start_id,\n",
    "                                eos_id,\n",
    "                                verbose=False)'''\n",
    "            #print('%d: POST COMPLETENESS SINGLE SAMPLE: %.2f' % (sampling_iter_idx, comp_2))\n",
    "    \n",
    "    if iter_idx % 500 == 0 and iter_idx != 0:\n",
    "        avg_valid_accuracy = 0.0\n",
    "        avg_valid_completeness = 0.0\n",
    "        \n",
    "        print('START VALIDATION:')\n",
    "        \n",
    "        for v_iter_idx, sit_id in enumerate(tqdm(valid_sit_id)):\n",
    "            utter_ids = sid2uids[sit_id]\n",
    "            \n",
    "            target_utters = id_select(utter_ids, utterances)\n",
    "            \n",
    "            input_sit_str = '^ ' + id_select([sit_id], situations)[0] + ' !'\n",
    "            input_sit = v1.tokenize(input_sit_str)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred_ids, _, logits_all = model_forward(input_sit.to(device),\n",
    "                                                        force=False,\n",
    "                                                        sample=False,\n",
    "                                                        tu_target=None,\n",
    "                                                        loss_func=None,\n",
    "                                                        gen_length=13)\n",
    "            \n",
    "            cleaned_pred = ' '.join(v2.decode(pred_ids)).replace('!', '').strip()\n",
    "            \n",
    "            if cleaned_pred in target_utters:\n",
    "                avg_valid_accuracy += 1\n",
    "            \n",
    "            if v_iter_idx < 100:\n",
    "                comp = beam_completeness(\n",
    "                            target_utters,\n",
    "                            input_sit.to(device),\n",
    "                            enc,\n",
    "                            dec,\n",
    "                            v2,\n",
    "                            start_id,\n",
    "                            eos_id,\n",
    "                            verbose=False)\n",
    "\n",
    "                avg_valid_completeness += comp\n",
    "        \n",
    "        avg_valid_accuracy /= len(valid_sit_id)\n",
    "        avg_valid_completeness /= 100\n",
    "        \n",
    "        plot.add(valid_accuracy=avg_valid_accuracy, valid_completeness=avg_valid_completeness)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH alexwan@128.32.176.101 honeydew (gbi3.7)",
   "language": "",
   "name": "rik_ssh_alexwan_128_32_176_101_honeydewgbi37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
